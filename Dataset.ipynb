{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479c680c-bb50-44db-82c7-80891b45df92",
   "metadata": {},
   "source": [
    "### Importing Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d35bbb5-84bc-4f58-ab35-24b44a528731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PMChatBot\\Bot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, TFAutoModel\n",
    "from transformers import pipeline\n",
    "from hazm import *\n",
    "import fasttext\n",
    "from hazm.utils import stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05e84bb-7ff9-44e9-8d04-82f7997db9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2b2d8-377e-4d7b-9505-8f8889524bec",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc31e79-1f4f-474f-8181-f334503cdc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"MeDiaPQ&A/MeDiaPQA.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a91f23-09ec-43c1-9e14-edfe0b66932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Q':'question', 'A':'answer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a25048-4dfd-41c4-92ba-ae23355870f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca33b8-3ef2-49d4-80fc-be80bb92f46d",
   "metadata": {},
   "source": [
    "### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfac0c-574f-4a5d-94ca-60660963efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _multiple_replace(mapping, text):\n",
    "    pattern = \"|\".join(map(re.escape, mapping.keys()))\n",
    "    return re.sub(pattern, lambda m: mapping[m.group()], str(text))\n",
    "\n",
    "def convert_fa_numbers(input_str):\n",
    "    mapping = {\n",
    "        '۰': '0',\n",
    "        '۱': '1',\n",
    "        '۲': '2',\n",
    "        '۳': '3',\n",
    "        '۴': '4',\n",
    "        '۵': '5',\n",
    "        '۶': '6',\n",
    "        '۷': '7',\n",
    "        '۸': '8',\n",
    "        '۹': '9',\n",
    "        '.': '.',\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "\n",
    "def convert_ar_characters(input_str):\n",
    "    \"\"\"\n",
    "    Converts Arabic chars to related Persian unicode char\n",
    "    :param input_str: String contains Arabic chars\n",
    "    :return: New str with converted arabic chars\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی',\n",
    "        'ئ':'ی',\n",
    "        'إ':'ا',\n",
    "        'أ':'ا',\n",
    "        'ة':'ه',\n",
    "        'ؤ':'و'\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    #extractor = URLExtract()\n",
    "    #for url in extractor.gen_urls(text):\n",
    "    #    text = text.replace(url,'<URL>')\n",
    "    emj = emojis.get(text)\n",
    "    #emj = emoji\n",
    "    for i in emj:\n",
    "        if i in text:\n",
    "            text = text.replace(i,'<emoji>')\n",
    "    text = convert_fa_numbers(text)\n",
    "    text = convert_ar_characters(text)\n",
    "    # regex to detect and replace all smilies in the text with <smiley>\n",
    "    text = re.sub(r\"(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|:\\s?D|8-\\)|:\\s?\\||;\\s?\\)|:-\\*|:-\\||:-\\(|:\\s?P|:-P|:-p|:-b|:-O|:-o|:-0|:-\\@|:\\$|:-\\^|:-&|:-\\*|:-\\+|:-\\~|:-\\`|:-\\>|:-\\<|:-\\}|:-\\{|\\[:\\s?\\]|\\[:\\s?\\]|:\\s?\\]|:\\s?\\[|:\\s?\\}|:\\s?\\{)\",'<smiley>',text)\n",
    "    text = text.lower() # we lowercase here to prevent changes in the URLs and smilies\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[<>#.:()\"\\'!?؟،,@$%^&*_+\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'[\\s]{2,}', ' ', text)\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1',text)\n",
    "    if re.search(r'[\\u0600-\\u06FF]', text):\n",
    "        return(text)\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aff2da-4a73-4f3a-b810-7c40bea99f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a47eb-bb30-4b58-a471-35d03d117e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['questions'] = df['question'].progress_apply(preprocess)\n",
    "df['answers'] = df['answer'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66560f5-f834-4e1a-8bca-7c78f2eede67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3baf7-0cf3-4e73-9a45-128c439e48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['question', 'answer'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4803d3e3-14a3-4ab0-8db1-719e5676de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b683548-6552-434d-a337-cf882b51af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b8b3b-25d4-4804-b665-c7453d9f32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5bfc0-4fd5-4aec-8ebc-623026382c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('PMChatbot_Datasets_new.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9750878b-5cd7-4b97-baa0-bc8118298f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = stopwords_list()\n",
    "#df['Questions'] = df['questions'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "#df['Answers'] = df['answers'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74336b-ebd2-4b24-90b2-c985e32e5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1cbc99-9e19-4b56-b8ce-a66116fd615c",
   "metadata": {},
   "source": [
    "### NEW PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8cdfe-540f-40b3-b71a-7ef777aba9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"PMChatbot_Datasets_new.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b776579-8fef-4843-843d-40cbb435c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'questions':'QQ', 'answers':'AA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dcfd6-f03a-43ca-8b0d-06095a3a0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178cf42-4373-4c84-8d79-38389968c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QQ'] = df['QQ'].str.replace(\"\\u200c\", \" \")\n",
    "df['AA'] = df['AA'].str.replace(\"\\u200c\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0422da-8ddf-43b8-a607-7032bbc7cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('PMChatbot_Datasets_BESTnew.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fff488-d2e4-408a-8912-9dcad0d07621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# خواندن فایل اکسل\n",
    "df = pd.read_csv(\"PMChatbot_Datasets_BESTnew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e173071-21b8-4ab9-94b7-8998beed9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import WordTokenizer\n",
    "\n",
    "# ایجاد یک شیء برای توکن‌سازی کلمات\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "# تابع برای فاصله‌گذاری بین کلمات\n",
    "def add_spaces(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# اعمال تابع روی ستون مورد نظر\n",
    "df[\"QQ\"] = df[\"QQ\"].apply(add_spaces)\n",
    "df[\"AA\"] = df[\"AA\"].apply(add_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202e00c-573a-4388-9be9-f99d517227bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"QQ\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7313475-8120-487c-bd13-fe17b4d223e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import WordTokenizer\n",
    "\n",
    "# ایجاد یک شیء برای توکن‌سازی کلمات\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "# تابع برای فاصله‌گذاری بین کلمات\n",
    "def add_spaces(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# اعمال تابع روی ستون مورد نظر\n",
    "#df = df.apply(add_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabaa81-537b-4652-89e4-6deb412f58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [\"نمیادبایدچیکارکنم\"].apply(add_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375c012-d493-425a-bbe8-baf6838bbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hazm import WordTokenizer\n",
    "\n",
    "# ایجاد یک DataFrame از لیست\n",
    "df = pd.DataFrame([\"نمیادبایدچیکارکنم\"], columns=[\"متن\"])\n",
    "\n",
    "# ایجاد یک شیء برای توکن‌سازی کلمات\n",
    "tokenizer = WordTokenizer()\n",
    "\n",
    "# تابع برای فاصله‌گذاری بین کلمات\n",
    "def add_spaces(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# اعمال تابع روی ستون \"متن\"\n",
    "df[\"متن\"] = df[\"متن\"].apply(add_spaces)\n",
    "\n",
    "# نمایش نتیجه\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903a2af-68d2-4336-93ac-550c6f057e02",
   "metadata": {},
   "source": [
    "### ENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a97de6a-4eef-4f9f-ae55-ef1f4b26a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PMChatbot_Datasets_BESTnew.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b45b13b-f7e0-4497-b3bc-e62552ac3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_noise(text):\n",
    "    # حذف اموجی‌ها و کاراکترهای خاص\n",
    "    text = re.sub(r'[^\\w\\s\\u200c.,،؛!؟?]', '', text)\n",
    "    # حذف فاصله‌های اضافی\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fe6af5-7ac5-4b96-a36f-23c4139f1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QQ'] = df['QQ'].apply(remove_noise)\n",
    "df['AA'] = df['AA'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e29bbf-7216-4eca-aeb7-e0286adfd7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "df['QQ'] = df['QQ'].apply(normalizer.normalize)\n",
    "df['AA'] = df['AA'].apply(normalizer.normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984271de-e1b6-42e8-ad90-797c4b612496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['QQ'] = df['QQ'].str.replace(\"\\u200c\", \" \")\n",
    "#df['AA'] = df['AA'].str.replace(\"\\u200c\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff04136-bff5-436b-83a8-3a9560728424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_specific_words(text):\n",
    "    # Dictionary for specific words, including the new separation\n",
    "    word_dict = {\n",
    "        \"دکترپسرم\":\"دکتر پسرم\",\n",
    "        \"پدربنده\":\"پدر بنده\",\n",
    "        \"دکترایشان\":\"دکتر ایشان\",\n",
    "        \"باردارنمی\":\"باردار نمی\",\n",
    "        \"افسرده_شدم\":\"افسرده شدم\",\n",
    "        \"داشته_باشد\":\"داشته باشد\",\n",
    "        \"داده_بودم\":\"داده بودم\",\n",
    "        \"گرفته_بودم\":\"گرفته بودم\",\n",
    "        \"انگارکه\":\"انگار که\",\n",
    "        \"شده_اند\":\"شده اند\",\n",
    "        \"افتاده_است\":\"افتاده است\",\n",
    "        \"دکترحدود\":\"دکتر حدود\",\n",
    "        \"بهتراست\":\"بهتر است\",\n",
    "        \"دارمحتی\":\"دارم حتی\",\n",
    "        \"کاربکنیم\":\"کار بکنیم\",\n",
    "        \"بارداری\":\"بار داری\",\n",
    "        \"وسینورا\":\"و سینورا\",\n",
    "        \"اثرنکرد\":\"اثر نکرد\",\n",
    "        \"بالابود\":\"بالا بود\",\n",
    "        \"چهاربار\":\"چهار بار\",\n",
    "        \"شده_بود\":\" شده بود\",\n",
    "        \"شهریورماه\":\"شهریور ماه\",\n",
    "        \"دکتراجازه\":\"دکتر اجازه\",\n",
    "        \"ازامروز\":\"از امروز\",\n",
    "        \"بیشتراز\":\"بیشتر از\",\n",
    "        \"شدپرستارمجددا\":\"شد پرستار مجددا\",\n",
    "        \"ودراوردن\":\"و در اوردن\",\n",
    "        \"وکشیده\":\"و کشیده\",\n",
    "        \"بودموقع\":\"بود موقع\",\n",
    "        \"دوهفته\":\"دو هفته\",\n",
    "        \"نمیادباید\":\"نمی‌آید باید\",\n",
    "        \"نمی‌آیدباید\": \"نمی‌آید باید\",  # Separate \"نمی‌آید\" and \"باید\"\n",
    "        \"چیکارکنم\": \"چیکار کنم\",       # Separate \"چیکار\" and \"کنم\"\n",
    "        \"بایدچیکار\": \"باید چیکار\",     # Separate \"باید\" and \"چیکار\"  <-- Added this line\n",
    "        \n",
    "        # Add more words as needed...\n",
    "    }\n",
    "\n",
    "    # Replace joined words with separated versions\n",
    "    for word, replacement in word_dict.items():\n",
    "        text = text.replace(word, replacement)\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "#text = \"نمی‌آیدبایدچیکار کنم\"\n",
    "#separated_text = separate_specific_words(df['QQ'])\n",
    "#print(separated_text)  # Output: نمی‌آید باید چیکار کنم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a57b658-5f59-4e98-9c00-904d7eca4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QQ'] = df['QQ'].apply(separate_specific_words)\n",
    "df['AA'] = df['AA'].apply(separate_specific_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11816b27-43bc-4f85-af33-ab7b4275028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  QQ  \\\n",
      "0                                          سلام دکتر   \n",
      "1  من معاینه شدم ولی چیزی نگفتن فقط گفتن سونو اون...   \n",
      "2                                     سلام اقای دکتر   \n",
      "3  دوهفته پیش بابام یک شب بیمارستان بستری بودموقع...   \n",
      "4                               سلام خوبین آقای دکتر   \n",
      "\n",
      "                                           AA  \\\n",
      "0                                  سلام بفرما   \n",
      "1            خیر ازمایشات هورمونی انجامی دهید   \n",
      "2                               سلام بفرمایید   \n",
      "3  در این مورد به متخصص جراح کلیه مراجعه کنید   \n",
      "4                               مرسی بفرمایید   \n",
      "\n",
      "                               کلمات بهم چسبیده سوال کلمات بهم چسبیده جواب  \n",
      "0                                                 []                    []  \n",
      "1                                                 []   [ازمایشات, هورمونی]  \n",
      "2                                                 []            [بفرمایید]  \n",
      "3  [بیمارستان, بودموقع, دستشویی, ودراوردن, شدپرست...                    []  \n",
      "4                                                 []            [بفرمایید]  \n"
     ]
    }
   ],
   "source": [
    "from hazm import word_tokenize\n",
    "\n",
    "def find_joined_words(text):\n",
    "    # توکن‌سازی متن\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # شناسایی کلمات بهم چسبیده\n",
    "    joined_words = [token for token in tokens if len(token) > 6]  # حدس طول کلمات بهم چسبیده\n",
    "    return joined_words\n",
    "\n",
    "# اعمال تابع روی ستون متن\n",
    "df['کلمات بهم چسبیده سوال'] = separate_specific_words(df['QQ'].apply(find_joined_words))\n",
    "df['کلمات بهم چسبیده جواب'] = separate_specific_words(df['AA'].apply(find_joined_words))\n",
    "\n",
    "# نمایش داده‌های جدید\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "370eff66-3e78-42e0-a6c1-1f62086d4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دکترپسرم سه سالشه هنوز نمیتونه صحبت کنه صداش که می‌زنیم اهمیت نمیده و فقط به صداهای اطراف مانند تلویزیون اهمیت میده چیزی ازحرفاش هم خوب نمیشه فهمید فقط بابا یا گاهی هم مامان میگه هنوز چیزی میخواد اسمشو نمیگه چیکار کنم\n",
      "در اولین فرصت تست شنوایی‌ای بی آر رو انجام بدید\n"
     ]
    }
   ],
   "source": [
    "print(df['QQ'][230])\n",
    "print(df['AA'][230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57039a3b-7a5c-47c4-a486-942635cf5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['AA'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83bc1054-64db-488f-b10c-500b72cf2b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نتایج با موفقیت ذخیره شدند!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('end_output_file.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"نتایج با موفقیت ذخیره شدند!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5295f0e0-c591-41c6-bb24-06c1ab650caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import word_tokenize, sent_tokenize\n",
    "words = word_tokenize(separate_specific_words(df['QQ'][230]))\n",
    "sentences = sent_tokenize(separate_specific_words(df['QQ'][230]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fd40976-4baf-4035-8bc5-058c2b1caae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دو هفته پیش بابام یک شب بیمارستان بستری بود موقع دستشویی سنت و کشیده و در اوردن که خون زیادی اومد بعدش قطع شد پرستار مجددا سنت را وصل کرد گفت با ادرار اگه خون بیاد باید عمل بشه که خوشبختانه خون نیامد بیشتر از دو هفته مشکلی نداشت اما از امروز صبح ادرارش نمی‌آید باید چیکار کنم\n"
     ]
    }
   ],
   "source": [
    "print(separate_specific_words(df['QQ'][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc65c9-570b-4d14-854b-29df6bc1dfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f69cc-6e5b-4293-9021-8ed5775740e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf414b46-9559-4fa1-a844-732b49807287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جملات: ['سلام دکتر از زحمت\\u200cهای ما']\n"
     ]
    }
   ],
   "source": [
    "print(\"جملات:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e710dbc-8967-4d26-a90d-85686c414620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کلمات: ['دکترپسرم', 'سه', 'سالشه', 'هنوز', 'نمیتونه', 'صحبت', 'کنه', 'صداش', 'که', 'می\\u200cزنیم', 'اهمیت', 'نمیده', 'و', 'فقط', 'به', 'صداهای', 'اطراف', 'مانند', 'تلویزیون', 'اهمیت', 'میده', 'چیزی', 'ازحرفاش', 'هم', 'خوب', 'نمیشه', 'فهمید', 'فقط', 'بابا', 'یا', 'گاهی', 'هم', 'مامان', 'میگه', 'هنوز', 'چیزی', 'میخواد', 'اسمشو', 'نمیگه', 'چیکار', 'کنم']\n"
     ]
    }
   ],
   "source": [
    "print(\"کلمات:\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5979bb-2613-4eee-8a20-507e9db56f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
